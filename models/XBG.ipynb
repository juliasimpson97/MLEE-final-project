{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d4a327-8cd7-44a4-8dd8-42408dbdf992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 12:40:59.515840: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Machine learning libraries\n",
    "import sklearn            # machine-learning libary with many algorithms implemented\n",
    "import xgboost as xgb     # extreme gradient boosting (XGB)\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Python file with supporting functions\n",
    "import model_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfdfe9d-9b70-4498-af7c-a674e284d048",
   "metadata": {
    "tags": []
   },
   "source": [
    "### To Set and Track Seeds for Reproducibility (Referencing Group Standard):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb1ca43-1510-45a1-a93a-1c2665b35952",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = 'CESM'\n",
    "member = '009'\n",
    "reference_output_dir = '/home/julias/MLEE-final-project/pickle_files'\n",
    "\n",
    "path_seeds = f'{reference_output_dir}/random_seeds.npy'\n",
    "random_seeds = np.load(path_seeds)  \n",
    "\n",
    "path_loc = f'{reference_output_dir}/cesm_seed_loc_dict.pickle'\n",
    "with open(path_loc,'rb') as handle:\n",
    "    seed_loc_dict = pickle.load(handle)\n",
    "seed_loc = seed_loc_dict[ens][member]\n",
    "\n",
    "# for next project, where train and test datasets use all CESM members\n",
    "#path_cesm = f\"{reference_output_dir}/cesm_members_dict.pickle\"\n",
    "#with open(path_cesm,'rb') as handle:\n",
    "#    cesm_mems_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4bbf3be-038e-40c4-8249-a053077c769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf69a920-5995-4ec7-a297-d89b5aecfd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_loc_dict # using CESM 009, so seed_loc should be 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d866f5e-f197-44bd-81dc-2c06c9b054d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_loc #confirmed 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0058f0b5-1738-4b99-90d8-cec14106e72e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bring in split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ab1920-2888-423e-a973-1ce049de6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/X.nc').to_dataframe()\n",
    "y_df = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/y.nc').to_dataframe() \n",
    "X_train_df = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/X_train.nc').to_dataframe() \n",
    "y_train_df = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/y_train.nc').to_dataframe()\n",
    "X_test_df = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/X_test.nc').to_dataframe() \n",
    "y_test_df = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/y_test.nc').to_dataframe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2046ae73-ca29-4393-8832-0cc4b1d00437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unseen_df = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/X_unseen.nc').to_dataframe() \n",
    "y_unseen_df = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/y_unseen.nc').to_dataframe() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb5399-0ea5-4f94-9b57-4fbd075014b5",
   "metadata": {},
   "source": [
    "Check that data was saved and loaded properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea82734c-940d-408b-b025-a189f634c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "203ffe19-2966-43b9-95e0-61523faac91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af7a062-6087-483a-85d7-09e25ea603aa",
   "metadata": {},
   "source": [
    "## To test normalization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26996ba2-d2f3-4a15-86f3-b36b0f3dbe3a",
   "metadata": {},
   "source": [
    "*Note: Done here, as opposed to in test/train split, so that I can save the original train/test datasets and later determine whether normalization led to improvement. (My group has not historically normalized data before training.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "813b669d-15d4-4656-b599-b1c3d20cb670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_df_norm = (X_df - X_df.mean())/X_df.std() \n",
    "y_df_norm = (y_df - y_df.mean())/y_df.std()\n",
    "X_train_df_norm = (X_train_df - X_train_df.mean())/X_train_df.std()\n",
    "y_train_df_norm = (y_train_df - y_train_df.mean())/y_train_df.std()\n",
    "X_test_df_norm = (X_test_df - X_test_df.mean())/X_test_df.std()\n",
    "y_test_df_norm = (y_test_df - y_test_df.mean())/y_test_df.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687fc72f-3087-4d7b-adbc-e695794f8a0b",
   "metadata": {},
   "source": [
    "## Create numpy arrays for both regular and normalized dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd881f76-94f2-4b25-8626-95d24b48cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_df.to_numpy()         \n",
    "y = y_df.to_numpy().ravel() \n",
    "X_train = X_train_df.to_numpy() \n",
    "y_train = y_train_df.to_numpy().ravel()\n",
    "X_test = X_test_df.to_numpy()  \n",
    "y_test = y_test_df.to_numpy().ravel()\n",
    "\n",
    "X_n = X_df_norm.to_numpy()         \n",
    "y_n = y_df_norm.to_numpy().ravel() \n",
    "X_train_n = X_train_df_norm.to_numpy()\n",
    "y_train_n = y_train_df_norm.to_numpy().ravel()\n",
    "X_test_n = X_test_df_norm.to_numpy() \n",
    "y_test_n = y_test_df_norm.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f5104-0d54-4e5d-a47e-f798ede4a01a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## For future work: additional validation split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2103f0e0-3fea-4aaa-b9b0-7c30ec6f1000",
   "metadata": {},
   "source": [
    "*Note: Group does not use this method when test years are used (as I did in processed_data_split.ipynb)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8d65a-f85a-4e47-b972-f2a34ca89a2d",
   "metadata": {},
   "source": [
    "### Train/validate/test split proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31474571-24ca-41bc-880e-4abe8315cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% of dataset for validation, 20% of dataset for testing, the rest for training\n",
    "# Training set will be split into validation and another training set\n",
    "\n",
    "val_prop = .2\n",
    "test_prop = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19e5a2dd-2368-4bfc-8bee-20db6e25ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data into validation and another training set   \n",
    "N = X_train.shape[0]\n",
    "train_val_idx, train_idx, val_idx, test_idx = model_utils.train_val_test_split(N, test_prop, val_prop, random_seeds, seed_loc)\n",
    "X_train_val, X_train, X_val, X_test_tmp, y_train_val, y_train, y_val, y_test_tmp = model_utils.apply_splits(X_train, y_train, train_val_idx, train_idx, val_idx, test_idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be7cffee-5cf5-478f-81bf-48ccf0af3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5424fe9-51bf-4105-8b34-edd70b608eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_idx, test_idx = train_test_split(range(N), test_size=test_prop, random_state=random_seeds[0,seed_loc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b5b52b1-3e15-47d5-98e7-590c60a1298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_test_split(intermediate_idx, test_size=val_prop/(1-test_prop), random_state=random_seeds[1,seed_loc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ef31563-21dc-496c-abc4-6e9550e8f742",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4591642 is out of bounds for axis 0 with size 3833412",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train_val \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_val_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4591642 is out of bounds for axis 0 with size 3833412"
     ]
    }
   ],
   "source": [
    "X_train_val = X_train[train_val_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc381c0-b466-4147-996d-58b53c0a2a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75bc6bdb-349b-4c7e-bf61-01b0b3e05ada",
   "metadata": {
    "tags": []
   },
   "source": [
    "# eXtreme Gradient Boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa97e2de-a29a-4964-85f2-b0486af58e90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reference Best Parameters from Previous Group Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa52bb6-224d-450d-ad91-32a548620408",
   "metadata": {},
   "source": [
    "Published in Bennington 2022, trained XGB to learn pCO2 residual (pC02 change with direct temperature effects removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f02f55-b192-4b72-9e9b-80cbf9690ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bp='/data/artemis/workspace/vbennington/full_sst/pCO2_DIC/models/performance_metrics/xg/xg_best_params_dict.pickle'\n",
    "with open(path_bp,'rb') as handle:\n",
    "    best_params = pickle.load(handle)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe92973a-ac67-46df-b5ec-2f4785c2fe9a",
   "metadata": {},
   "source": [
    "Use previous CESM best parameters as a starting point:\n",
    "- max_depth = 6\n",
    "- n_estimators = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8856f467-b2a8-4595-bb51-d468d8b0057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with three different n_estimators and 3 different depths\n",
    "# Advice from group post-doc: For XGB, too many depth layers may lead to overfitting (usually 8 or less layers for XGB)\n",
    "# We want the combo of xg_param_grid that gives the lowest RMSE\n",
    "\n",
    "xg_param_grid = {'n_estimators':[3000, 4000, 5000],\n",
    "                 'max_depth':[5, 6, 7]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad4546-8ab0-4083-8db9-8a22a98a8bbb",
   "metadata": {},
   "source": [
    "(to compare performance to other methods from group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d078c8-648e-4337-89c5-8808539a5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For next step of testing new hyperparameters, clear best_params\n",
    "# best_params = {}  # opened above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5174b327-7c31-47d1-ba93-7459e06a9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A, B and C represent lon and lat (3 components of the n-vector; so that the algorithm doesn't interpret 0 and 360\n",
    "# degrees to be far apart \n",
    "# T0 and T1 represent time\n",
    "\n",
    "#features_sel = ['SSS','SST','MLD','Chl','XCO2','T0', 'T1','A', 'B', 'C'] \n",
    "#target_sel = ['pCO2'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b859ca1-fc16-4a8e-9e67-585ae7947ca5",
   "metadata": {},
   "source": [
    "## Building and Training the XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4561be-a79e-4011-9c6f-aa0b76a58b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cores you have access to for model training, group standard:\n",
    "jobs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6aa460-0e12-43ce-aab9-21130913f6a7",
   "metadata": {},
   "source": [
    "### Create two dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dcf1c8-e2ce-41d8-81d0-6cbde968421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance = defaultdict(dict)\n",
    "unseen_performance = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239ccc10-6a9e-4145-b253-4172b8e74c85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGB-Specific Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335086e-79de-4ffd-bafe-cadda5f609d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_folds: cross validation; number of splits for training set (in this case 3 splits; see below)\n",
    "# Train on the first split, test on the remaining 2. Total 3 numbers for the final RMSE\n",
    "\n",
    "K_folds = 3       # Split training set into 3 parts\n",
    "approach = \"xg\"   # XGB approach\n",
    "#first_mem = False # Initialize if using gridsearch to find best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605d100-f504-45bd-a9a7-40d54db20498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: define which approach to use\n",
    "# param_grid: the n_estimators (decision trees) and depths\n",
    "# GridSearchCV: applying the K-fold cross validation\n",
    "# first_mem = False: checks only the best params for first_mem (and not all members). For the next members, the  \n",
    "# parameters from first_mem are re-used\n",
    "# you could try to find the best params for a few members (but not all of them)\n",
    "# 9 possible combinations (3 different n_estimators, 3 different max depths) x 3 (K-fold; 3 training sets)\n",
    "if first_mem:\n",
    "            model = XGBRegressor(random_state=random_seeds[4,seed_loc], n_jobs=jobs)\n",
    "            param_grid = xg_param_grid\n",
    "            grid = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=K_folds, return_train_score=False, refit=False)\n",
    "            grid.fit(X_train_val, y_train_val)\n",
    "            best_params[ens] = grid.best_params_\n",
    "            print(best_params)\n",
    "            first_mem = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2a8a8-b2ff-4db8-960f-d3083707ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(random_state=random_seeds[4,seed_loc], n_jobs=jobs)\n",
    "param_grid = xg_param_grid\n",
    "grid = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=K_folds, return_train_score=False, refit=False)\n",
    "grid.fit(X_train, y_train)\n",
    "best_params[ens] = grid.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e418d5-98b5-4c7f-9f07-7e725ec11a34",
   "metadata": {},
   "source": [
    "### Train the XBG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68372057-6ec0-4130-b691-8f6eee9b2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(random_state=random_seeds[5,seed_loc], **best_params[ens], n_jobs=jobs)\n",
    "model.fit(X_train_val, y_train_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefd2b9-8e53-4592-8447-deb80acd5eb5",
   "metadata": {},
   "source": [
    "### Save the XBG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d270f81-95e3-4340-b4e6-312a5b853547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment when actually running\n",
    "\n",
    "# pre_saildrone now called utils, carry through this change\n",
    "utils.save_model(model, model_output_dir, approach, ens, member)\n",
    "print(datetime.datetime.now())\n",
    "print(ens)\n",
    "print(member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753ff10-7234-42c1-b909-2efb8f95abcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cf1228a-c2b7-4c40-bf4e-15c7fb89e18d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing the XGB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7939f4-a636-40fb-99b0-ba0b672356ca",
   "metadata": {},
   "source": [
    "### Preliminary Analysis on XBG Test Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c896294-3fc1-4646-b806-6325024309ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some test error metrics and store in a dictionary\n",
    "# evaluate_test is a function from pre_saildrone. it includes MSE, MAE, bias etc\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "test_performance[ens][member] = utils.evaluate_test(y_test, y_pred_test)\n",
    "print(test_performance[ens][member])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ada10-0949-4490-8ffa-835c8c2d752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo this analysis on the unseen data\n",
    "y_pred_unseen = model.predict(df.loc[unseen_sel,features_sel].to_numpy())\n",
    "\n",
    "y_unseen = df.loc[unseen_sel,target_sel].to_numpy().ravel()\n",
    "unseen_performance[ens][member] = utils.evaluate_test(y_unseen, y_pred_unseen)\n",
    "print(unseen_performance[ens][member])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a42e6-f71c-4a4d-bcf6-05c06cdb7ed9",
   "metadata": {},
   "source": [
    "## Create the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052448e-6953-4b26-9624-a73cccfd323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reconstruction and save it\n",
    "# Jake calls it seen\n",
    "# This should just be all SOCAT locations for all training years (not test years)\n",
    "y_pred_seen = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ed4e3-ef33-4b4d-bdc1-52f1d9729020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full reconstruction \n",
    "df['pCO2_DIC_recon'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_recon']] = y_pred_unseen   # Not in a SOCAT location, not even in test year\n",
    "df.loc[sel,['pCO2_DIC_recon']] = y_pred_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2358cbb0-77cf-473d-851e-aac9731ad12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All time/locations not sampled by SOCAT\n",
    "df['pCO2_DIC_nosocat'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_nosocat']] = y_pred_unseen\n",
    "df.loc[sel,['pCO2_DIC_nosocat']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340f160-9f1c-43b5-884c-b89b0d731d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only at time/locations of SOCAT sampling\n",
    "df['pCO2_DIC_socat'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_socat']] = np.nan\n",
    "df.loc[sel,['pCO2_DIC_socat']] = y_pred_seen\n",
    "     \n",
    "df['pCO2_DIC'] = df['pCO2_pCO2T_diff']\n",
    "             \n",
    "#DS_recon = df[['net_mask','socat_mask','pCO2_DIC','pCO2_DIC_recon','pCO2_DIC_socat','pCO2_DIC_nosocat']].to_xarray()\n",
    "DS_recon = df[['net_mask','combined_mask','pCO2_DIC','pCO2_DIC_recon','pCO2_DIC_socat','pCO2_DIC_nosocat']].to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0228e59-170a-44b9-9e8d-d19497b459ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0306d-5e20-42da-abf8-45b6452570d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when actually running            \n",
    "#pre_saildrone_thea.save_recon(DS_recon, recon_output_dir, approach, ens, member)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8577729-ce28-40b5-a58a-dab22f4398e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save best parameters and performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef554ad3-d62d-4d07-ad17-887eeac70403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving best parameters and performance metrics\n",
    "\n",
    "approach_output_dir = f\"{other_output_dir}/{approach}\"\n",
    "param_fname = f\"{approach_output_dir}/{approach}_best_params_dict.pickle\"\n",
    "test_perform_fname = f\"{approach_output_dir}/{approach}_test_performance_dict.pickle\"\n",
    "unseen_perform_fname = f\"{approach_output_dir}/{approach}_unseen_performance_dict.pickle\"\n",
    "\n",
    "Path(approach_output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(param_fname, 'wb') as handle: #WHAT DOES wb MEAN\n",
    "    pickle.dump(best_params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(test_perform_fname, 'wb') as handle:\n",
    "    pickle.dump(test_performance, handle)\n",
    "with open(unseen_perform_fname, 'wb') as handle:\n",
    "    pickle.dump(unseen_performance, handle)\n",
    "    \n",
    "# Convert performance metrics to dataframes\n",
    "test_df = pd.DataFrame.from_dict({(i,j): test_performance[i][j]\n",
    "                                  for i in test_performance.keys()\n",
    "                                  for j in test_performance[i].keys()},\n",
    "                                 orient='index')\n",
    "\n",
    "unseen_df = pd.DataFrame.from_dict({(i,j): unseen_performance[i][j]\n",
    "                                  for i in unseen_performance.keys()\n",
    "                                  for j in unseen_performance[i].keys()},\n",
    "                                 orient='index')\n",
    "\n",
    "test_df.index.names = [\"model\",\"member\"]\n",
    "unseen_df.index.names = [\"model\",\"member\"]\n",
    "\n",
    "# Save the dataframes too\n",
    "test_df_fname = f\"{approach_output_dir}/{approach}_test_performance_df.pickle\"\n",
    "unseen_df_fname = f\"{approach_output_dir}/{approach}_unseen_performance_df.pickle\"\n",
    "\n",
    "test_df.to_pickle(test_df_fname)\n",
    "unseen_df.to_pickle(unseen_df_fname)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958183d4-aedf-4a16-8e42-182080456877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd061ac1-4b01-4871-8a34-b5ae2d7f7364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3eb81-9636-47cb-9897-639b812646b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a98afb-ef0e-4371-b658-03a6c9c076ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just checking what the saved trained datafiles look like \n",
    "test_2 = pd.read_pickle(\"/data/artemis/workspace/theimdal/saildrone/models/trained/xg/CESM/member_016/xg_model_pC02_2D_mon_CESM_016_1x1_198201-201701.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e386a-0d9e-4965-97b3-378fd9ab13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0786f53-4477-4fdb-b643-d94adb6e2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking out what the input data for the XGB looks like\n",
    "#this table was generated in script 01\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4069f-7878-462b-965c-2adbad08dba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fromML",
   "language": "python",
   "name": "fromml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
