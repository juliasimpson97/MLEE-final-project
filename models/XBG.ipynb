{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d4a327-8cd7-44a4-8dd8-42408dbdf992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-03 17:58:54.017100: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Machine learning libraries\n",
    "import sklearn            # machine-learning libary with many algorithms implemented\n",
    "import xgboost as xgb     # extreme gradient boosting (XGB)\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Python file with supporting functions\n",
    "import model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57ab1920-2888-423e-a973-1ce049de6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/X.nc') \n",
    "y = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/y.nc') \n",
    "X_train = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/X_train.nc') \n",
    "y_train = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/y_train.nc') \n",
    "X_test = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/X_test.nc') \n",
    "y_test = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/y_test.nc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046ae73-ca29-4393-8832-0cc4b1d00437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unseen = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/X_unseen.nc') \n",
    "y_unseen = xr.open_dataset('/home/julias/MLEE-final-project/proc_data/split_datasets/y_unseen.nc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea82734c-940d-408b-b025-a189f634c3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SSS</th>\n",
       "      <th>SST</th>\n",
       "      <th>MLD</th>\n",
       "      <th>Chl</th>\n",
       "      <th>XCO2</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlon</th>\n",
       "      <th>ylat</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-179.5</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-77.5</th>\n",
       "      <th>1996-12-15</th>\n",
       "      <td>34.519566</td>\n",
       "      <td>-1.687043</td>\n",
       "      <td>214.616638</td>\n",
       "      <td>2.408046</td>\n",
       "      <td>362.937073</td>\n",
       "      <td>0.966848</td>\n",
       "      <td>-0.255353</td>\n",
       "      <td>-0.976296</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>0.216431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-01-15</th>\n",
       "      <td>34.359451</td>\n",
       "      <td>0.538524</td>\n",
       "      <td>18.861521</td>\n",
       "      <td>7.900837</td>\n",
       "      <td>363.078552</td>\n",
       "      <td>0.966848</td>\n",
       "      <td>0.255353</td>\n",
       "      <td>-0.976296</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>0.216431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-15</th>\n",
       "      <td>34.372940</td>\n",
       "      <td>-0.129260</td>\n",
       "      <td>48.051937</td>\n",
       "      <td>8.482795</td>\n",
       "      <td>365.225403</td>\n",
       "      <td>0.966848</td>\n",
       "      <td>0.255353</td>\n",
       "      <td>-0.976296</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>0.216431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-15</th>\n",
       "      <td>34.287220</td>\n",
       "      <td>2.750365</td>\n",
       "      <td>19.898767</td>\n",
       "      <td>0.205808</td>\n",
       "      <td>368.928192</td>\n",
       "      <td>0.702527</td>\n",
       "      <td>0.711657</td>\n",
       "      <td>-0.976296</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>0.216431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-15</th>\n",
       "      <td>34.288605</td>\n",
       "      <td>-0.362210</td>\n",
       "      <td>22.430550</td>\n",
       "      <td>8.158799</td>\n",
       "      <td>374.658783</td>\n",
       "      <td>0.966848</td>\n",
       "      <td>0.255353</td>\n",
       "      <td>-0.976296</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>0.216431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">179.5</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">78.5</th>\n",
       "      <th>1990-07-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-12-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-11-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-12-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988-11-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17747280 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               SSS       SST         MLD       Chl  \\\n",
       "xlon   ylat  time                                                    \n",
       "-179.5 -77.5 1996-12-15  34.519566 -1.687043  214.616638  2.408046   \n",
       "             1997-01-15  34.359451  0.538524   18.861521  7.900837   \n",
       "             1998-01-15  34.372940 -0.129260   48.051937  8.482795   \n",
       "             2000-02-15  34.287220  2.750365   19.898767  0.205808   \n",
       "             2003-01-15  34.288605 -0.362210   22.430550  8.158799   \n",
       "...                            ...       ...         ...       ...   \n",
       " 179.5  78.5 1990-07-15        NaN       NaN         NaN       NaN   \n",
       "             1990-12-15        NaN       NaN         NaN       NaN   \n",
       "             1989-11-15        NaN       NaN         NaN       NaN   \n",
       "             1989-12-15        NaN       NaN         NaN       NaN   \n",
       "             1988-11-15        NaN       NaN         NaN       NaN   \n",
       "\n",
       "                               XCO2        T0        T1         A         B  \\\n",
       "xlon   ylat  time                                                             \n",
       "-179.5 -77.5 1996-12-15  362.937073  0.966848 -0.255353 -0.976296 -0.001889   \n",
       "             1997-01-15  363.078552  0.966848  0.255353 -0.976296 -0.001889   \n",
       "             1998-01-15  365.225403  0.966848  0.255353 -0.976296 -0.001889   \n",
       "             2000-02-15  368.928192  0.702527  0.711657 -0.976296 -0.001889   \n",
       "             2003-01-15  374.658783  0.966848  0.255353 -0.976296 -0.001889   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       " 179.5  78.5 1990-07-15         NaN       NaN       NaN       NaN       NaN   \n",
       "             1990-12-15         NaN       NaN       NaN       NaN       NaN   \n",
       "             1989-11-15         NaN       NaN       NaN       NaN       NaN   \n",
       "             1989-12-15         NaN       NaN       NaN       NaN       NaN   \n",
       "             1988-11-15         NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "                                C  \n",
       "xlon   ylat  time                  \n",
       "-179.5 -77.5 1996-12-15  0.216431  \n",
       "             1997-01-15  0.216431  \n",
       "             1998-01-15  0.216431  \n",
       "             2000-02-15  0.216431  \n",
       "             2003-01-15  0.216431  \n",
       "...                           ...  \n",
       " 179.5  78.5 1990-07-15       NaN  \n",
       "             1990-12-15       NaN  \n",
       "             1989-11-15       NaN  \n",
       "             1989-12-15       NaN  \n",
       "             1988-11-15       NaN  \n",
       "\n",
       "[17747280 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "203ffe19-2966-43b9-95e0-61523faac91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pCO2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlon</th>\n",
       "      <th>ylat</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-179.5</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-77.5</th>\n",
       "      <th>1997-02-15</th>\n",
       "      <td>166.861496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-15</th>\n",
       "      <td>174.326938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-11-15</th>\n",
       "      <td>313.570954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-15</th>\n",
       "      <td>185.846402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-15</th>\n",
       "      <td>173.178833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">179.5</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">73.5</th>\n",
       "      <th>1983-10-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-09-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-04-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-06-15</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4465080 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               pCO2\n",
       "xlon   ylat  time                  \n",
       "-179.5 -77.5 1997-02-15  166.861496\n",
       "             2005-01-15  174.326938\n",
       "             2005-11-15  313.570954\n",
       "             2007-02-15  185.846402\n",
       "             2015-01-15  173.178833\n",
       "...                             ...\n",
       " 179.5  73.5 1983-10-15         NaN\n",
       "             1986-09-15         NaN\n",
       "             1991-04-15         NaN\n",
       "             1995-01-15         NaN\n",
       "             1985-06-15         NaN\n",
       "\n",
       "[4465080 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af7a062-6087-483a-85d7-09e25ea603aa",
   "metadata": {},
   "source": [
    "## If do standardization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26996ba2-d2f3-4a15-86f3-b36b0f3dbe3a",
   "metadata": {},
   "source": [
    "*Note: Done here, as opposed to in test/train split, so that I can save the original train/test datasets and later determine whether normalization led to improvement. (My group has not historically normalized data before training.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b669d-15d4-4656-b599-b1c3d20cb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = (X - X.mean())/X.std() \n",
    "y_norm = (y - y.mean())/y.std()\n",
    "X_train_norm = (X_train - X_train.mean())/X_train.std()\n",
    "y_train_norm = (y_train - y_train.mean())/y_train.std()\n",
    "X_test_norm = (X_test - X_test.mean())/X_test.std()\n",
    "y_test_norm = (y_test - y_test.mean())/y_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff019f13-55c1-497d-bd75-d2238903d8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f68f5104-0d54-4e5d-a47e-f798ede4a01a",
   "metadata": {},
   "source": [
    "## If do additional validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8d65a-f85a-4e47-b972-f2a34ca89a2d",
   "metadata": {},
   "source": [
    "### Train/validate/test split proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31474571-24ca-41bc-880e-4abe8315cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% of dataset for validation, 20% of dataset for testing, the rest for training\n",
    "# Training set will be split into validation and another training set\n",
    "\n",
    "val_prop = .2\n",
    "test_prop = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b64184-33d1-4796-949c-9a4cf1548840",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = X.to_numpy()         \n",
    "yn = y.to_numpy().ravel()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c187a-5bf5-4220-8c16-40b2cb3edc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd881f76-94f2-4b25-8626-95d24b48cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_n = Xtrain.to_numpy() # create Xtrain and Xtest to randomly select from for X_train and X_test\n",
    "ytrain_n = ytrain.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e919424-ee02-412c-be66-33b8174a5795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't use X_test_tmp or y_test_tmp when test years are used (X_test and y_test set above)\n",
    "X_test_n = X_test.to_numpy()  #  Test metrics on all of SOCAT data from test years\n",
    "y_test_n = y_test.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac70b6f-b649-4111-802c-1195ebe3e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After re-import all the datasets, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645db73-f3bc-4924-aa79-db08d35b77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data into validation and another training set   \n",
    "#N = Xtrain.shape[0]\n",
    "#train_val_idx, train_idx, val_idx, test_idx = proc_utils.train_val_test_split(N, test_prop, val_prop, random_seeds, seed_loc)\n",
    "#X_train_val, X_train, X_val, X_test_tmp, y_train_val, y_train, y_val, y_test_tmp = proc_utils.apply_splits(Xtrain, ytrain, train_val_idx, train_idx, val_idx, test_idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e5a2dd-2368-4bfc-8bee-20db6e25ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data into validation and another training set   \n",
    "N = Xtrain.shape[0]\n",
    "train_val_idx, train_idx, val_idx, test_idx = proc_utils.train_val_test_split(N, test_prop, val_prop, random_seeds, seed_loc)\n",
    "X_train_val, X_train, X_val, X_test_tmp, y_train_val, y_train, y_val, y_test_tmp = proc_utils.apply_splits(Xtrain, ytrain, train_val_idx, train_idx, val_idx, test_idx) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc6bdb-349b-4c7e-bf61-01b0b3e05ada",
   "metadata": {
    "tags": []
   },
   "source": [
    "# eXtreme Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5174b327-7c31-47d1-ba93-7459e06a9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A, B and C represent lon and lat (3 components of the n-vector; so that the algorithm doesn't interpret 0 and 360\n",
    "# degrees to be far apart \n",
    "# T0 and T1 represent time\n",
    "\n",
    "#features_sel = ['SSS','SST','MLD','Chl','XCO2','T0', 'T1','A', 'B', 'C'] \n",
    "#target_sel = ['pCO2'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0571d4b-4f52-4e7b-b7ad-303fd6eaec4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Referencing Group Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfdfe9d-9b70-4498-af7c-a674e284d048",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### If chose to track seeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acb1ca43-1510-45a1-a93a-1c2665b35952",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_loc,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m      8\u001b[0m     seed_loc_dict \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[0;32m----> 9\u001b[0m seed_loc \u001b[38;5;241m=\u001b[39m seed_loc_dict[\u001b[43mens\u001b[49m][member]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ens' is not defined"
     ]
    }
   ],
   "source": [
    "ens = 'CESM'\n",
    "member = '009'\n",
    "reference_output_dir = '/home/julias/MLEE-final-project/pickle_files'\n",
    "\n",
    "path_seeds = f'{reference_output_dir}/random_seeds.npy'\n",
    "random_seeds = np.load(path_seeds)  \n",
    "\n",
    "path_loc = f'{reference_output_dir}/cesm_seed_loc_dict.pickle'\n",
    "with open(path_loc,'rb') as handle:\n",
    "    seed_loc_dict = pickle.load(handle)\n",
    "seed_loc = seed_loc_dict[ens][member]\n",
    "\n",
    "# for next project, where train and test datasets use all CESM members\n",
    "#path_cesm = f\"{reference_output_dir}/cesm_members_dict.pickle\"\n",
    "#with open(path_cesm,'rb') as handle:\n",
    "#    cesm_mems_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4bbf3be-038e-40c4-8249-a053077c769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf69a920-5995-4ec7-a297-d89b5aecfd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_loc_dict # using CESM 009, so seed_loc should be 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d866f5e-f197-44bd-81dc-2c06c9b054d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_loc #confirmed 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa97e2de-a29a-4964-85f2-b0486af58e90",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reference Best Parameters from Previous Group Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa52bb6-224d-450d-ad91-32a548620408",
   "metadata": {},
   "source": [
    "Published in Bennington 2022, trained XGB to learn pCO2 residual (pC02 change with direct temperature effects removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52f02f55-b192-4b72-9e9b-80cbf9690ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CESM': {'max_depth': 6, 'n_estimators': 4000}, 'GFDL': {'max_depth': 6, 'n_estimators': 4000}, 'MPI': {'max_depth': 6, 'n_estimators': 4000}, 'CanESM2': {'max_depth': 6, 'n_estimators': 4000}}\n"
     ]
    }
   ],
   "source": [
    "path_bp='/data/artemis/workspace/vbennington/full_sst/pCO2_DIC/models/performance_metrics/xg/xg_best_params_dict.pickle'\n",
    "with open(path_bp,'rb') as handle:\n",
    "    best_params = pickle.load(handle)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe92973a-ac67-46df-b5ec-2f4785c2fe9a",
   "metadata": {},
   "source": [
    "Use previous CESM best parameters as a starting point:\n",
    "- max_depth = 6\n",
    "- n_estimators = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8856f467-b2a8-4595-bb51-d468d8b0057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with three different n_estimators and 3 different depths\n",
    "# Advice from group post-doc: For XGB, too many depth layers may lead to overfitting (usually 8 or less layers for XGB)\n",
    "# We want the combo of xg_param_grid that gives the lowest RMSE\n",
    "\n",
    "xg_param_grid = {'n_estimators':[3000, 4000, 5000],\n",
    "                 'max_depth':[5, 6, 7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1d445-1fe7-400d-adb7-bb73ac85e2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31effeff-260c-443d-b33b-c9f8111e989f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3ad4546-8ab0-4083-8db9-8a22a98a8bbb",
   "metadata": {},
   "source": [
    "(to compare performance to other methods from group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36590480-1faa-42d7-b14f-0f0f21c8fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name everything with XGB\n",
    "# will be Notebook B in 3_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b859ca1-fc16-4a8e-9e67-585ae7947ca5",
   "metadata": {},
   "source": [
    "## Building and Training the XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dcf1c8-e2ce-41d8-81d0-6cbde968421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = {}  # opened above\n",
    "# defaultdict is from a package #which one, does what\n",
    "\n",
    "test_performance = defaultdict(dict)\n",
    "unseen_performance = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4561be-a79e-4011-9c6f-aa0b76a58b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Number of cores you have access to for model training\n",
    "# =========================================\n",
    "jobs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6aa460-0e12-43ce-aab9-21130913f6a7",
   "metadata": {},
   "source": [
    "### Create two dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239ccc10-6a9e-4145-b253-4172b8e74c85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGB-Specific Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335086e-79de-4ffd-bafe-cadda5f609d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_folds: cross validation; number of splits for training set (in this case 3 splits; see below)\n",
    "# Train on the first split, test on the remaining 2. Total 3 numbers for the final RMSE\n",
    "\n",
    "K_folds = 3       # Split training set into 3 parts\n",
    "approach = \"xg\"   # XGB approach\n",
    "first_mem = False # Initialize if using gridsearch to find best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605d100-f504-45bd-a9a7-40d54db20498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: define which approach to use\n",
    "# param_grid: the n_estimators (decision trees) and depths\n",
    "# GridSearchCV: applying the K-fold cross validation\n",
    "# first_mem = False: checks only the best params for first_mem (and not all members). For the next members, the  \n",
    "# parameters from first_mem are re-used\n",
    "# you could try to find the best params for a few members (but not all of them)\n",
    "# 9 possible combinations (3 different n_estimators, 3 different max depths) x 3 (K-fold; 3 training sets)\n",
    "if first_mem:\n",
    "            model = XGBRegressor(random_state=random_seeds[4,seed_loc], n_jobs=jobs)\n",
    "            param_grid = xg_param_grid\n",
    "            grid = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=K_folds, return_train_score=False, refit=False)\n",
    "            grid.fit(X_train_val, y_train_val)\n",
    "            best_params[ens] = grid.best_params_\n",
    "            print(best_params)\n",
    "            first_mem = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e418d5-98b5-4c7f-9f07-7e725ec11a34",
   "metadata": {},
   "source": [
    "### Train the XBG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68372057-6ec0-4130-b691-8f6eee9b2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(random_state=random_seeds[5,seed_loc], **best_params[ens], n_jobs=jobs)\n",
    "model.fit(X_train_val, y_train_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefd2b9-8e53-4592-8447-deb80acd5eb5",
   "metadata": {},
   "source": [
    "### Save the XBG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d270f81-95e3-4340-b4e6-312a5b853547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment when actually running\n",
    "\n",
    "# pre_saildrone now called utils, carry through this change\n",
    "utils.save_model(model, model_output_dir, approach, ens, member)\n",
    "print(datetime.datetime.now())\n",
    "print(ens)\n",
    "print(member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753ff10-7234-42c1-b909-2efb8f95abcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cf1228a-c2b7-4c40-bf4e-15c7fb89e18d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing the XGB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7939f4-a636-40fb-99b0-ba0b672356ca",
   "metadata": {},
   "source": [
    "### Preliminary Analysis on XBG Test Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c896294-3fc1-4646-b806-6325024309ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some test error metrics and store in a dictionary\n",
    "# evaluate_test is a function from pre_saildrone. it includes MSE, MAE, bias etc\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "test_performance[ens][member] = utils.evaluate_test(y_test, y_pred_test)\n",
    "print(test_performance[ens][member])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ada10-0949-4490-8ffa-835c8c2d752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo this analysis on the unseen data\n",
    "y_pred_unseen = model.predict(df.loc[unseen_sel,features_sel].to_numpy())\n",
    "\n",
    "y_unseen = df.loc[unseen_sel,target_sel].to_numpy().ravel()\n",
    "unseen_performance[ens][member] = utils.evaluate_test(y_unseen, y_pred_unseen)\n",
    "print(unseen_performance[ens][member])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a42e6-f71c-4a4d-bcf6-05c06cdb7ed9",
   "metadata": {},
   "source": [
    "## Create the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052448e-6953-4b26-9624-a73cccfd323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reconstruction and save it\n",
    "# Jake calls it seen\n",
    "# This should just be all SOCAT locations for all training years (not test years)\n",
    "y_pred_seen = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ed4e3-ef33-4b4d-bdc1-52f1d9729020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full reconstruction \n",
    "df['pCO2_DIC_recon'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_recon']] = y_pred_unseen   # Not in a SOCAT location, not even in test year\n",
    "df.loc[sel,['pCO2_DIC_recon']] = y_pred_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2358cbb0-77cf-473d-851e-aac9731ad12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All time/locations not sampled by SOCAT\n",
    "df['pCO2_DIC_nosocat'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_nosocat']] = y_pred_unseen\n",
    "df.loc[sel,['pCO2_DIC_nosocat']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340f160-9f1c-43b5-884c-b89b0d731d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only at time/locations of SOCAT sampling\n",
    "df['pCO2_DIC_socat'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_socat']] = np.nan\n",
    "df.loc[sel,['pCO2_DIC_socat']] = y_pred_seen\n",
    "     \n",
    "df['pCO2_DIC'] = df['pCO2_pCO2T_diff']\n",
    "             \n",
    "#DS_recon = df[['net_mask','socat_mask','pCO2_DIC','pCO2_DIC_recon','pCO2_DIC_socat','pCO2_DIC_nosocat']].to_xarray()\n",
    "DS_recon = df[['net_mask','combined_mask','pCO2_DIC','pCO2_DIC_recon','pCO2_DIC_socat','pCO2_DIC_nosocat']].to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0228e59-170a-44b9-9e8d-d19497b459ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0306d-5e20-42da-abf8-45b6452570d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when actually running            \n",
    "#pre_saildrone_thea.save_recon(DS_recon, recon_output_dir, approach, ens, member)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8577729-ce28-40b5-a58a-dab22f4398e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save best parameters and performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef554ad3-d62d-4d07-ad17-887eeac70403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving best parameters and performance metrics\n",
    "\n",
    "approach_output_dir = f\"{other_output_dir}/{approach}\"\n",
    "param_fname = f\"{approach_output_dir}/{approach}_best_params_dict.pickle\"\n",
    "test_perform_fname = f\"{approach_output_dir}/{approach}_test_performance_dict.pickle\"\n",
    "unseen_perform_fname = f\"{approach_output_dir}/{approach}_unseen_performance_dict.pickle\"\n",
    "\n",
    "Path(approach_output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(param_fname, 'wb') as handle: #WHAT DOES wb MEAN\n",
    "    pickle.dump(best_params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(test_perform_fname, 'wb') as handle:\n",
    "    pickle.dump(test_performance, handle)\n",
    "with open(unseen_perform_fname, 'wb') as handle:\n",
    "    pickle.dump(unseen_performance, handle)\n",
    "    \n",
    "# Convert performance metrics to dataframes\n",
    "test_df = pd.DataFrame.from_dict({(i,j): test_performance[i][j]\n",
    "                                  for i in test_performance.keys()\n",
    "                                  for j in test_performance[i].keys()},\n",
    "                                 orient='index')\n",
    "\n",
    "unseen_df = pd.DataFrame.from_dict({(i,j): unseen_performance[i][j]\n",
    "                                  for i in unseen_performance.keys()\n",
    "                                  for j in unseen_performance[i].keys()},\n",
    "                                 orient='index')\n",
    "\n",
    "test_df.index.names = [\"model\",\"member\"]\n",
    "unseen_df.index.names = [\"model\",\"member\"]\n",
    "\n",
    "# Save the dataframes too\n",
    "test_df_fname = f\"{approach_output_dir}/{approach}_test_performance_df.pickle\"\n",
    "unseen_df_fname = f\"{approach_output_dir}/{approach}_unseen_performance_df.pickle\"\n",
    "\n",
    "test_df.to_pickle(test_df_fname)\n",
    "unseen_df.to_pickle(unseen_df_fname)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958183d4-aedf-4a16-8e42-182080456877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd061ac1-4b01-4871-8a34-b5ae2d7f7364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3eb81-9636-47cb-9897-639b812646b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a98afb-ef0e-4371-b658-03a6c9c076ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just checking what the saved trained datafiles look like \n",
    "test_2 = pd.read_pickle(\"/data/artemis/workspace/theimdal/saildrone/models/trained/xg/CESM/member_016/xg_model_pC02_2D_mon_CESM_016_1x1_198201-201701.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e386a-0d9e-4965-97b3-378fd9ab13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0786f53-4477-4fdb-b643-d94adb6e2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking out what the input data for the XGB looks like\n",
    "#this table was generated in script 01\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4069f-7878-462b-965c-2adbad08dba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fromML",
   "language": "python",
   "name": "fromml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
