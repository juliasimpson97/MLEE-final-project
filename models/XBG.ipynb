{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4a327-8cd7-44a4-8dd8-42408dbdf992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Machine learning libraries\n",
    "import sklearn            # machine-learning libary with many algorithms implemented\n",
    "import xgboost as xgb     # extreme gradient boosting (XGB)\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Python file with supporting functions\n",
    "import model_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc6bdb-349b-4c7e-bf61-01b0b3e05ada",
   "metadata": {
    "tags": []
   },
   "source": [
    "# eXtreme Gradient Boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad4546-8ab0-4083-8db9-8a22a98a8bbb",
   "metadata": {},
   "source": [
    "(to compare performance to other methods from group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36590480-1faa-42d7-b14f-0f0f21c8fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name everything with XGB\n",
    "# will be Notebook B in 3_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b859ca1-fc16-4a8e-9e67-585ae7947ca5",
   "metadata": {},
   "source": [
    "## Building and Training the XGB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239ccc10-6a9e-4145-b253-4172b8e74c85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGB-Specific Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335086e-79de-4ffd-bafe-cadda5f609d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_folds: cross validation; number of splits for training set (in this case 3 splits; see below)\n",
    "# Train on the first split, test on the remaining 2. Total 3 numbers for the final RMSE\n",
    "\n",
    "K_folds = 3       # Split training set into 3 parts\n",
    "approach = \"xg\"   # XGB approach\n",
    "first_mem = False # Initialize if using gridsearch to find best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605d100-f504-45bd-a9a7-40d54db20498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: define which approach to use\n",
    "# param_grid: the n_estimators (decision trees) and depths\n",
    "# GridSearchCV: applying the K-fold cross validation\n",
    "# first_mem = False: checks only the best params for first_mem (and not all members). For the next members, the  \n",
    "# parameters from first_mem are re-used\n",
    "# you could try to find the best params for a few members (but not all of them)\n",
    "# 9 possible combinations (3 different n_estimators, 3 different max depths) x 3 (K-fold; 3 training sets)\n",
    "if first_mem:\n",
    "            model = XGBRegressor(random_state=random_seeds[4,seed_loc], n_jobs=jobs)\n",
    "            param_grid = xg_param_grid\n",
    "            grid = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=K_folds, return_train_score=False, refit=False)\n",
    "            grid.fit(X_train_val, y_train_val)\n",
    "            best_params[ens] = grid.best_params_\n",
    "            print(best_params)\n",
    "            first_mem = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e418d5-98b5-4c7f-9f07-7e725ec11a34",
   "metadata": {},
   "source": [
    "### Train the XBG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68372057-6ec0-4130-b691-8f6eee9b2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(random_state=random_seeds[5,seed_loc], **best_params[ens], n_jobs=jobs)\n",
    "model.fit(X_train_val, y_train_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefd2b9-8e53-4592-8447-deb80acd5eb5",
   "metadata": {},
   "source": [
    "### Save the XBG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d270f81-95e3-4340-b4e6-312a5b853547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment when actually running\n",
    "\n",
    "# pre_saildrone now called utils, carry through this change\n",
    "utils.save_model(model, model_output_dir, approach, ens, member)\n",
    "print(datetime.datetime.now())\n",
    "print(ens)\n",
    "print(member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753ff10-7234-42c1-b909-2efb8f95abcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cf1228a-c2b7-4c40-bf4e-15c7fb89e18d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing the XGB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7939f4-a636-40fb-99b0-ba0b672356ca",
   "metadata": {},
   "source": [
    "### Preliminary Analysis on XBG Test Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c896294-3fc1-4646-b806-6325024309ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some test error metrics and store in a dictionary\n",
    "# evaluate_test is a function from pre_saildrone. it includes MSE, MAE, bias etc\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "test_performance[ens][member] = utils.evaluate_test(y_test, y_pred_test)\n",
    "print(test_performance[ens][member])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ada10-0949-4490-8ffa-835c8c2d752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo this analysis on the unseen data\n",
    "y_pred_unseen = model.predict(df.loc[unseen_sel,features_sel].to_numpy())\n",
    "\n",
    "y_unseen = df.loc[unseen_sel,target_sel].to_numpy().ravel()\n",
    "unseen_performance[ens][member] = utils.evaluate_test(y_unseen, y_pred_unseen)\n",
    "print(unseen_performance[ens][member])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a42e6-f71c-4a4d-bcf6-05c06cdb7ed9",
   "metadata": {},
   "source": [
    "## Create the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052448e-6953-4b26-9624-a73cccfd323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reconstruction and save it\n",
    "# Jake calls it seen\n",
    "# This should just be all SOCAT locations for all training years (not test years)\n",
    "y_pred_seen = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ed4e3-ef33-4b4d-bdc1-52f1d9729020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full reconstruction \n",
    "df['pCO2_DIC_recon'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_recon']] = y_pred_unseen   # Not in a SOCAT location, not even in test year\n",
    "df.loc[sel,['pCO2_DIC_recon']] = y_pred_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2358cbb0-77cf-473d-851e-aac9731ad12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All time/locations not sampled by SOCAT\n",
    "df['pCO2_DIC_nosocat'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_nosocat']] = y_pred_unseen\n",
    "df.loc[sel,['pCO2_DIC_nosocat']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340f160-9f1c-43b5-884c-b89b0d731d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only at time/locations of SOCAT sampling\n",
    "df['pCO2_DIC_socat'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_socat']] = np.nan\n",
    "df.loc[sel,['pCO2_DIC_socat']] = y_pred_seen\n",
    "     \n",
    "df['pCO2_DIC'] = df['pCO2_pCO2T_diff']\n",
    "             \n",
    "#DS_recon = df[['net_mask','socat_mask','pCO2_DIC','pCO2_DIC_recon','pCO2_DIC_socat','pCO2_DIC_nosocat']].to_xarray()\n",
    "DS_recon = df[['net_mask','combined_mask','pCO2_DIC','pCO2_DIC_recon','pCO2_DIC_socat','pCO2_DIC_nosocat']].to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0228e59-170a-44b9-9e8d-d19497b459ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0306d-5e20-42da-abf8-45b6452570d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when actually running            \n",
    "#pre_saildrone_thea.save_recon(DS_recon, recon_output_dir, approach, ens, member)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8577729-ce28-40b5-a58a-dab22f4398e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save best parameters and performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef554ad3-d62d-4d07-ad17-887eeac70403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving best parameters and performance metrics\n",
    "\n",
    "approach_output_dir = f\"{other_output_dir}/{approach}\"\n",
    "param_fname = f\"{approach_output_dir}/{approach}_best_params_dict.pickle\"\n",
    "test_perform_fname = f\"{approach_output_dir}/{approach}_test_performance_dict.pickle\"\n",
    "unseen_perform_fname = f\"{approach_output_dir}/{approach}_unseen_performance_dict.pickle\"\n",
    "\n",
    "Path(approach_output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(param_fname, 'wb') as handle: #WHAT DOES wb MEAN\n",
    "    pickle.dump(best_params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(test_perform_fname, 'wb') as handle:\n",
    "    pickle.dump(test_performance, handle)\n",
    "with open(unseen_perform_fname, 'wb') as handle:\n",
    "    pickle.dump(unseen_performance, handle)\n",
    "    \n",
    "# Convert performance metrics to dataframes\n",
    "test_df = pd.DataFrame.from_dict({(i,j): test_performance[i][j]\n",
    "                                  for i in test_performance.keys()\n",
    "                                  for j in test_performance[i].keys()},\n",
    "                                 orient='index')\n",
    "\n",
    "unseen_df = pd.DataFrame.from_dict({(i,j): unseen_performance[i][j]\n",
    "                                  for i in unseen_performance.keys()\n",
    "                                  for j in unseen_performance[i].keys()},\n",
    "                                 orient='index')\n",
    "\n",
    "test_df.index.names = [\"model\",\"member\"]\n",
    "unseen_df.index.names = [\"model\",\"member\"]\n",
    "\n",
    "# Save the dataframes too\n",
    "test_df_fname = f\"{approach_output_dir}/{approach}_test_performance_df.pickle\"\n",
    "unseen_df_fname = f\"{approach_output_dir}/{approach}_unseen_performance_df.pickle\"\n",
    "\n",
    "test_df.to_pickle(test_df_fname)\n",
    "unseen_df.to_pickle(unseen_df_fname)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958183d4-aedf-4a16-8e42-182080456877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd061ac1-4b01-4871-8a34-b5ae2d7f7364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3eb81-9636-47cb-9897-639b812646b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a98afb-ef0e-4371-b658-03a6c9c076ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just checking what the saved trained datafiles look like \n",
    "test_2 = pd.read_pickle(\"/data/artemis/workspace/theimdal/saildrone/models/trained/xg/CESM/member_016/xg_model_pC02_2D_mon_CESM_016_1x1_198201-201701.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e386a-0d9e-4965-97b3-378fd9ab13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0786f53-4477-4fdb-b643-d94adb6e2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking out what the input data for the XGB looks like\n",
    "#this table was generated in script 01\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4069f-7878-462b-965c-2adbad08dba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fromML",
   "language": "python",
   "name": "fromml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
