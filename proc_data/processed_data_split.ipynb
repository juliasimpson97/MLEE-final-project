{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This file trains the XGBoost models and creates the reconstructions. \n",
    "\n",
    "Test months are separated from training and evaluation years like Bennington et al. (2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# For accessing directories\n",
    "# =========================================\n",
    "\n",
    "root_dir = '/home/julias/MLEE-final-project' \n",
    "data_output_dir = f'{root_dir}/proc_data'\n",
    "model_output_dir = f'{root_dir}/models'\n",
    "#recon_output_dir = f'{root_dir}/models/reconstructions'\n",
    "#other_output_dir = f'{root_dir}/models/performance_metrics'\n",
    "#approach = 'XGB'\n",
    "#approach_output_dir = f\"{other_output_dir}/{approach}\"\n",
    "#reference_output_dir = f\"{root_dir}/pickle_files\" #need to change, won't have full data pickle files on git --> or is this member dict etc only? how done when only ran with 1 model?\n",
    "\n",
    "#reference_output_dir = f\"/data/artemis/workspace/vbennington/full_sst/gregor_years/references\"\n",
    "#jake_other_output_dir = '/data/artemis/workspace/jfs2167/recon_eval/models/performance_metrics'\n",
    "\n",
    "# =========================================\n",
    "# Number of cores you have access to for model training\n",
    "# =========================================\n",
    "jobs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Machine learning libraries\n",
    "import sklearn            # machine-learning libary with many algorithms implemented\n",
    "import xgboost as xgb     # extreme gradient boosting (XGB)\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Python file with supporting functions\n",
    "import proc_utils #pre_saildrone_thea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bring in pre-processed data\n",
    "Data was imported in raw_data, pre-processed using import_data.ipynb and data_utils.py, and then saved to proc_data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = 'CESM'\n",
    "member = '009'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when creating multiple from testbed, will do:\n",
    "# data_dir = f\"{data_output_dir}/{ens}/member_{member}\"\n",
    "# fname = f'proc_data_2D_mon_{ens}_{member}_1x1_198202-201701.nc'\n",
    "# file_path = f\"{data_dir}/{fname}\"\n",
    "\n",
    "# here, project only focuses on CESM Member 009\n",
    "fname = f'proc_data_2D_mon_{ens}_{member}_1x1_198202-201701.nc'\n",
    "file_path = f'{data_output_dir}/{fname}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SSS</th>\n",
       "      <th>SST</th>\n",
       "      <th>MLD</th>\n",
       "      <th>Chl</th>\n",
       "      <th>pCO2</th>\n",
       "      <th>socat_mask</th>\n",
       "      <th>net_mask</th>\n",
       "      <th>XCO2</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlon</th>\n",
       "      <th>ylat</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-179.5</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-89.5</th>\n",
       "      <th>1982-02-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.848541</td>\n",
       "      <td>0.702527</td>\n",
       "      <td>0.711657</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-03-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.962250</td>\n",
       "      <td>0.292600</td>\n",
       "      <td>0.956235</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-04-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341.075439</td>\n",
       "      <td>-0.234491</td>\n",
       "      <td>0.972118</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-05-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341.193176</td>\n",
       "      <td>-0.683919</td>\n",
       "      <td>0.729558</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-06-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341.310730</td>\n",
       "      <td>-0.959933</td>\n",
       "      <td>0.280231</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">179.5</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">89.5</th>\n",
       "      <th>2016-09-15</th>\n",
       "      <td>31.799175</td>\n",
       "      <td>-1.705077</td>\n",
       "      <td>18.321320</td>\n",
       "      <td>2.740259</td>\n",
       "      <td>262.587131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.045654</td>\n",
       "      <td>-0.251190</td>\n",
       "      <td>-0.967938</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-15</th>\n",
       "      <td>31.790358</td>\n",
       "      <td>-1.793757</td>\n",
       "      <td>23.279984</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>305.656131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.276947</td>\n",
       "      <td>0.259512</td>\n",
       "      <td>-0.965740</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-15</th>\n",
       "      <td>31.931990</td>\n",
       "      <td>-1.799327</td>\n",
       "      <td>33.931915</td>\n",
       "      <td>0.045596</td>\n",
       "      <td>339.048261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.508392</td>\n",
       "      <td>0.714673</td>\n",
       "      <td>-0.699458</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-15</th>\n",
       "      <td>32.034790</td>\n",
       "      <td>-1.801694</td>\n",
       "      <td>46.475067</td>\n",
       "      <td>0.021913</td>\n",
       "      <td>359.252983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.739502</td>\n",
       "      <td>0.966848</td>\n",
       "      <td>-0.255353</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-15</th>\n",
       "      <td>32.136246</td>\n",
       "      <td>-1.800700</td>\n",
       "      <td>57.481308</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>379.529046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.971283</td>\n",
       "      <td>0.966848</td>\n",
       "      <td>0.255353</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27216000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               SSS       SST        MLD       Chl        pCO2  \\\n",
       "xlon   ylat  time                                                               \n",
       "-179.5 -89.5 1982-02-15        NaN       NaN        NaN       NaN         NaN   \n",
       "             1982-03-15        NaN       NaN        NaN       NaN         NaN   \n",
       "             1982-04-15        NaN       NaN        NaN       NaN         NaN   \n",
       "             1982-05-15        NaN       NaN        NaN       NaN         NaN   \n",
       "             1982-06-15        NaN       NaN        NaN       NaN         NaN   \n",
       "...                            ...       ...        ...       ...         ...   \n",
       " 179.5  89.5 2016-09-15  31.799175 -1.705077  18.321320  2.740259  262.587131   \n",
       "             2016-10-15  31.790358 -1.793757  23.279984  0.999385  305.656131   \n",
       "             2016-11-15  31.931990 -1.799327  33.931915  0.045596  339.048261   \n",
       "             2016-12-15  32.034790 -1.801694  46.475067  0.021913  359.252983   \n",
       "             2017-01-15  32.136246 -1.800700  57.481308  0.014401  379.529046   \n",
       "\n",
       "                         socat_mask  net_mask        XCO2        T0        T1  \\\n",
       "xlon   ylat  time                                                               \n",
       "-179.5 -89.5 1982-02-15         NaN       NaN  340.848541  0.702527  0.711657   \n",
       "             1982-03-15         NaN       NaN  340.962250  0.292600  0.956235   \n",
       "             1982-04-15         NaN       NaN  341.075439 -0.234491  0.972118   \n",
       "             1982-05-15         NaN       NaN  341.193176 -0.683919  0.729558   \n",
       "             1982-06-15         NaN       NaN  341.310730 -0.959933  0.280231   \n",
       "...                             ...       ...         ...       ...       ...   \n",
       " 179.5  89.5 2016-09-15         NaN       NaN  406.045654 -0.251190 -0.967938   \n",
       "             2016-10-15         NaN       NaN  406.276947  0.259512 -0.965740   \n",
       "             2016-11-15         NaN       NaN  406.508392  0.714673 -0.699458   \n",
       "             2016-12-15         NaN       NaN  406.739502  0.966848 -0.255353   \n",
       "             2017-01-15         NaN       NaN  406.971283  0.966848  0.255353   \n",
       "\n",
       "                                A         B         C  \n",
       "xlon   ylat  time                                      \n",
       "-179.5 -89.5 1982-02-15 -0.999962 -0.000076  0.008726  \n",
       "             1982-03-15 -0.999962 -0.000076  0.008726  \n",
       "             1982-04-15 -0.999962 -0.000076  0.008726  \n",
       "             1982-05-15 -0.999962 -0.000076  0.008726  \n",
       "             1982-06-15 -0.999962 -0.000076  0.008726  \n",
       "...                           ...       ...       ...  \n",
       " 179.5  89.5 2016-09-15  0.999962  0.000076  0.008726  \n",
       "             2016-10-15  0.999962  0.000076  0.008726  \n",
       "             2016-11-15  0.999962  0.000076  0.008726  \n",
       "             2016-12-15  0.999962  0.000076  0.008726  \n",
       "             2017-01-15  0.999962  0.000076  0.008726  \n",
       "\n",
       "[27216000 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = xr.open_dataset(file_path)\n",
    "df = ds.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Referencing Group Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## If chose to track seeds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading references\n",
    "# This is exactly the same as in 01_datasets_LET\n",
    "\n",
    "#path_LET = f\"{reference_output_dir}/members_LET_dict.pickle\"\n",
    "path_seeds = f\"{reference_output_dir}/random_seeds.npy\"\n",
    "path_loc = f\"{reference_output_dir}/members_seed_loc_dict.pickle\"\n",
    "\n",
    "#with open(path_LET,'rb') as handle:\n",
    "#    mems_dict = pickle.load(handle)\n",
    "    \n",
    "random_seeds = np.load(path_seeds)    \n",
    "    \n",
    "with open(path_loc,'rb') as handle:\n",
    "    seed_loc_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_loc = seed_loc_dict[ens][member] #think can comment out line, just define CESM 009 above\n",
    "#print(ens) #think can comment out line, just define CESM 009 above\n",
    "#print(member) #think can comment out line, just define CESM 009 above\n",
    "#seed_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mems_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_loc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Printing Best Params from other pCO2_Residual Run (Bennington 2022?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just showing the best parameters from another pCO2-Residual run (the ones that give the lowest RMSE)\n",
    "# 4000 n_estimators and 6 levels\n",
    "# n_estimators: 4000 decision trees\n",
    "# levels: defining the decision trees (number of splits)\n",
    "\n",
    "path_bp=\"/data/artemis/workspace/vbennington/full_sst/pCO2_DIC/models/performance_metrics/xg/xg_best_params_dict.pickle\"\n",
    "with open(path_bp,'rb') as handle:\n",
    "    best_params = pickle.load(handle)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with three different n_estimators and 3 different depths\n",
    "# NB: For XGB, too many depth layers may lead to overfitting (usually 8 or less layers for XGB)\n",
    "# We want the combo of xg_param_grid that gives the lowest RMSE\n",
    "\n",
    "xg_param_grid = {\"n_estimators\":[2000, 3000, 4000],\n",
    "                 \"max_depth\":[4, 5, 6]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training and testing ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SSS</th>\n",
       "      <th>SST</th>\n",
       "      <th>MLD</th>\n",
       "      <th>Chl</th>\n",
       "      <th>pCO2</th>\n",
       "      <th>socat_mask</th>\n",
       "      <th>net_mask</th>\n",
       "      <th>XCO2</th>\n",
       "      <th>T0</th>\n",
       "      <th>T1</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>year</th>\n",
       "      <th>mon</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlon</th>\n",
       "      <th>ylat</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-179.5</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-89.5</th>\n",
       "      <th>1982-02-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.848541</td>\n",
       "      <td>0.702527</td>\n",
       "      <td>0.711657</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>1982</td>\n",
       "      <td>2</td>\n",
       "      <td>1982-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-03-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340.962250</td>\n",
       "      <td>0.292600</td>\n",
       "      <td>0.956235</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>1982</td>\n",
       "      <td>3</td>\n",
       "      <td>1982-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-04-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341.075439</td>\n",
       "      <td>-0.234491</td>\n",
       "      <td>0.972118</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>1982</td>\n",
       "      <td>4</td>\n",
       "      <td>1982-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-05-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341.193176</td>\n",
       "      <td>-0.683919</td>\n",
       "      <td>0.729558</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>1982</td>\n",
       "      <td>5</td>\n",
       "      <td>1982-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-06-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341.310730</td>\n",
       "      <td>-0.959933</td>\n",
       "      <td>0.280231</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>1982</td>\n",
       "      <td>6</td>\n",
       "      <td>1982-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">179.5</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">89.5</th>\n",
       "      <th>2016-09-15</th>\n",
       "      <td>31.799175</td>\n",
       "      <td>-1.705077</td>\n",
       "      <td>18.321320</td>\n",
       "      <td>2.740259</td>\n",
       "      <td>262.587131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.045654</td>\n",
       "      <td>-0.251190</td>\n",
       "      <td>-0.967938</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-15</th>\n",
       "      <td>31.790358</td>\n",
       "      <td>-1.793757</td>\n",
       "      <td>23.279984</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>305.656131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.276947</td>\n",
       "      <td>0.259512</td>\n",
       "      <td>-0.965740</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-15</th>\n",
       "      <td>31.931990</td>\n",
       "      <td>-1.799327</td>\n",
       "      <td>33.931915</td>\n",
       "      <td>0.045596</td>\n",
       "      <td>339.048261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.508392</td>\n",
       "      <td>0.714673</td>\n",
       "      <td>-0.699458</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-15</th>\n",
       "      <td>32.034790</td>\n",
       "      <td>-1.801694</td>\n",
       "      <td>46.475067</td>\n",
       "      <td>0.021913</td>\n",
       "      <td>359.252983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.739502</td>\n",
       "      <td>0.966848</td>\n",
       "      <td>-0.255353</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>2016-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-15</th>\n",
       "      <td>32.136246</td>\n",
       "      <td>-1.800700</td>\n",
       "      <td>57.481308</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>379.529046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.971283</td>\n",
       "      <td>0.966848</td>\n",
       "      <td>0.255353</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27216000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               SSS       SST        MLD       Chl        pCO2  \\\n",
       "xlon   ylat  time                                                               \n",
       "-179.5 -89.5 1982-02-15        NaN       NaN        NaN       NaN         NaN   \n",
       "             1982-03-15        NaN       NaN        NaN       NaN         NaN   \n",
       "             1982-04-15        NaN       NaN        NaN       NaN         NaN   \n",
       "             1982-05-15        NaN       NaN        NaN       NaN         NaN   \n",
       "             1982-06-15        NaN       NaN        NaN       NaN         NaN   \n",
       "...                            ...       ...        ...       ...         ...   \n",
       " 179.5  89.5 2016-09-15  31.799175 -1.705077  18.321320  2.740259  262.587131   \n",
       "             2016-10-15  31.790358 -1.793757  23.279984  0.999385  305.656131   \n",
       "             2016-11-15  31.931990 -1.799327  33.931915  0.045596  339.048261   \n",
       "             2016-12-15  32.034790 -1.801694  46.475067  0.021913  359.252983   \n",
       "             2017-01-15  32.136246 -1.800700  57.481308  0.014401  379.529046   \n",
       "\n",
       "                         socat_mask  net_mask        XCO2        T0        T1  \\\n",
       "xlon   ylat  time                                                               \n",
       "-179.5 -89.5 1982-02-15         NaN       NaN  340.848541  0.702527  0.711657   \n",
       "             1982-03-15         NaN       NaN  340.962250  0.292600  0.956235   \n",
       "             1982-04-15         NaN       NaN  341.075439 -0.234491  0.972118   \n",
       "             1982-05-15         NaN       NaN  341.193176 -0.683919  0.729558   \n",
       "             1982-06-15         NaN       NaN  341.310730 -0.959933  0.280231   \n",
       "...                             ...       ...         ...       ...       ...   \n",
       " 179.5  89.5 2016-09-15         NaN       NaN  406.045654 -0.251190 -0.967938   \n",
       "             2016-10-15         NaN       NaN  406.276947  0.259512 -0.965740   \n",
       "             2016-11-15         NaN       NaN  406.508392  0.714673 -0.699458   \n",
       "             2016-12-15         NaN       NaN  406.739502  0.966848 -0.255353   \n",
       "             2017-01-15         NaN       NaN  406.971283  0.966848  0.255353   \n",
       "\n",
       "                                A         B         C  year  mon year_month  \n",
       "xlon   ylat  time                                                            \n",
       "-179.5 -89.5 1982-02-15 -0.999962 -0.000076  0.008726  1982    2     1982-2  \n",
       "             1982-03-15 -0.999962 -0.000076  0.008726  1982    3     1982-3  \n",
       "             1982-04-15 -0.999962 -0.000076  0.008726  1982    4     1982-4  \n",
       "             1982-05-15 -0.999962 -0.000076  0.008726  1982    5     1982-5  \n",
       "             1982-06-15 -0.999962 -0.000076  0.008726  1982    6     1982-6  \n",
       "...                           ...       ...       ...   ...  ...        ...  \n",
       " 179.5  89.5 2016-09-15  0.999962  0.000076  0.008726  2016    9     2016-9  \n",
       "             2016-10-15  0.999962  0.000076  0.008726  2016   10    2016-10  \n",
       "             2016-11-15  0.999962  0.000076  0.008726  2016   11    2016-11  \n",
       "             2016-12-15  0.999962  0.000076  0.008726  2016   12    2016-12  \n",
       "             2017-01-15  0.999962  0.000076  0.008726  2017    1     2017-1  \n",
       "\n",
       "[27216000 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'] = df.index.get_level_values('time').year \n",
    "df['mon'] = df.index.get_level_values('time').month \n",
    "df['year_month'] = df['year'].astype(str) + \"-\" + df['mon'].astype(str) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make lists for training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_dates = [] # Training set (this will be split in validation and another training set)\n",
    "test_dates = []   # Test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split testing years / create test year mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define date vector range of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: testbed starts in 1982\n",
    "date_range_start = '1982-02' #so change to 1982?\n",
    "date_range_end = '2017-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1982-02-15 00:00:00')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.get_level_values('time').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MS: beginning of each month + 14 --> each month starts on the 15th #again, why\n",
    "\n",
    "dates = pd.date_range(start=date_range_start, \n",
    "                      end=date_range_end,freq='MS') + np.timedelta64(14, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1982-02-15', '1982-03-15', '1982-04-15', '1982-05-15',\n",
       "               '1982-06-15', '1982-07-15', '1982-08-15', '1982-09-15',\n",
       "               '1982-10-15', '1982-11-15',\n",
       "               ...\n",
       "               '2016-04-15', '2016-05-15', '2016-06-15', '2016-07-15',\n",
       "               '2016-08-15', '2016-09-15', '2016-10-15', '2016-11-15',\n",
       "               '2016-12-15', '2017-01-15'],\n",
       "              dtype='datetime64[ns]', length=420, freq=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Want to train with 4 out of every 5 months, and test on the fifth month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i % 5 != 0: i cannot be divided by 5 without resulting in a remainder (will not give 0, i.e., i is not divisible by 5)\n",
    "# i % ==0: i can be divided by 5 without resulting in a remainder. i is divisible by 5\n",
    "\n",
    "for i in range(0,len(dates)):\n",
    "    if i % 5 != 0:\n",
    "        select_dates.append(dates[i]) #training set. train on all months but the 5th\n",
    "    if i % 5 == 0:\n",
    "        test_dates.append(dates[i])   #testing set. test on the 5th month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dates of training set into YEAR and MONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_mon = [] #making a list for the training set\n",
    "\n",
    "for i in range(0,len(select_dates)):\n",
    "    tmp = select_dates[i]\n",
    "    year_mon.append(f\"{tmp.year}-{tmp.month}\") #what is tmp/do i need to create that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dates of test set into YEAR and MONTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_year_mon = [] #making a list for the test set\n",
    "\n",
    "for i in range(0,len(test_dates)):\n",
    "    tmp = test_dates[i]\n",
    "    test_year_mon.append(f\"{tmp.year}-{tmp.month}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(year_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_year_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test_year_mon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Inputs Across Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/validate/test split proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% of dataset for validation, 20% of dataset for testing, the rest for training\n",
    "# Training set will be split into validation and another training set\n",
    "\n",
    "val_prop = .2\n",
    "test_prop = .2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and target lists for feeding into the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A, B and C represent lon and lat (3 components of the n-vector; so that the algorithm doesn't interpret 0 and 360\n",
    "# degrees to be far apart \n",
    "# T0 and T1 represent time\n",
    "\n",
    "features_sel = ['SSS','SST','MLD','Chl','XCO2','T0', 'T1','A', 'B', 'C'] \n",
    "target_sel = ['pCO2'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating two dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = {}  # opened above\n",
    "# defaultdict is from a package #which one, does what\n",
    "\n",
    "test_performance = defaultdict(dict)\n",
    "unseen_performance = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Unmasked locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE -250 to 250 FILTER, not looking at residual, maybe use 200 to 600 instead? look at data to decide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pCO2.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pCO2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pCO2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations from net_mask and NOT locations from SOCAT or Saildrone\n",
    "# net_mask is from network_mask in pre_saildrone: defines open ocean\n",
    "# removes: coast, bathymetry < 100 m, arctic ocean, Hudson Bay, caspian, black, mediterranean, baltic, Java sea & Red sea \n",
    "# range -250 to 250: realistic pCO2 values (this must be pCO2-Residual values?) \n",
    "# features_sel: SST, SSS, MLD etc #defined above\n",
    "# target_sel: pCO2-Residual #defined above\n",
    "# ~ means opposite; i.e., select only where net_mask is NOT a NaN\n",
    "\n",
    "# WHAT DOES RAVEL DO?\n",
    "recon_sel = (~df[features_sel+target_sel+['net_mask']].isna().any(axis=1)) & ((df[target_sel] < 250) \n",
    "                                                        & (df[target_sel] > -250)).to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.net_mask.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Masked locations (SOCAT + Saildrone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations not masked (open ocean) + SOCAT sampling OR!! saildrone sampling\n",
    "\n",
    "# Val's version:      \n",
    "#sel = (recon_sel & ((df['socat_mask'] == 1) | (df['sail_mask']==1)))\n",
    "\n",
    "#my version:\n",
    "sel = (recon_sel & (df['combined_mask'] == 1)) #I'll have just socat mask *do i need to import that nc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unseen_sel: selection of \"unseen\" data, i.e., locations that are unmasked (LET that is not picked by SOCAT and Saildrone)\n",
    "# locations not masked, not ridiculous pCO2, and NOT in SOCAT or saildrone sampling\n",
    "# wouldn't recon_sel and unseen_sel be the same?\n",
    "\n",
    "# Val's version:\n",
    "#unseen_sel = (recon_sel & (df['socat_mask'] == 0) & (np.isnan(df['sail_mask'])))  \n",
    "\n",
    "# my version:\n",
    "unseen_sel = (recon_sel & (np.isnan(df['combined_mask']))) #I'll have just socat mask *do i need to import that nc?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Make sure not to train and test on same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the TRAINING - makes sure to pick year + month from LET data ('year_month') that is not \n",
    "# in the 5th month (defined by year_mon in cell earlier)  \n",
    "train_sel = (sel & (pd.Series(df['year_month']).isin(year_mon))).to_numpy().ravel()\n",
    "print(sum(train_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the TESTING - makes sure to pick year + month from LET data ('year_month') that is  \n",
    "# in the 5th month (defined by test_year_mon in cell earlier).\n",
    "test_sel = (sel & (pd.Series(df['year_month']).isin(test_year_mon))).to_numpy().ravel()\n",
    "print(sum(test_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Convert dataframe to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val/test split ALL of the data (FULL dataset)\n",
    "X = df.loc[sel,features_sel].to_numpy()         \n",
    "y = df.loc[sel,target_sel].to_numpy().ravel()       # why this raveled and other not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting training and validation sets\n",
    "Xtrain = df.loc[train_sel,features_sel].to_numpy() # create Xtrain and Xtest to randomly select from for X_train and X_test\n",
    "ytrain = df.loc[train_sel,target_sel].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data into validation and another training set   \n",
    "N = Xtrain.shape[0]\n",
    "train_val_idx, train_idx, val_idx, test_idx = pre_saildrone_thea.train_val_test_split(N, test_prop, val_prop, random_seeds, seed_loc)\n",
    "X_train_val, X_train, X_val, X_test_tmp, y_train_val, y_train, y_val, y_test_tmp = pre_saildrone_thea.apply_splits(Xtrain, ytrain, train_val_idx, train_idx, val_idx, test_idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't use X_test_tmp or y_test_tmp when test years are used (X_test and y_test set above)\n",
    "X_test = df.loc[test_sel,features_sel].to_numpy()  #  Test metrics on all of SOCAT data from test years\n",
    "y_test = df.loc[test_sel,target_sel].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT DOES \"we don't use X_test_tmp etc when test years are used mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: define which approach to use\n",
    "# param_grid: the n_estimators (decision trees) and depths\n",
    "# GridSearchCV: applying the K-fold cross validation\n",
    "# first_mem = False: checks only the best params for first_mem (and not all members). For the next members, the  \n",
    "# parameters from first_mem are re-used\n",
    "# you could try to find the best params for a few members (but not all of them)\n",
    "# 9 possible combinations (3 different n_estimators, 3 different max depths) x 3 (K-fold; 3 training sets)\n",
    "if first_mem:\n",
    "            model = XGBRegressor(random_state=random_seeds[4,seed_loc], n_jobs=jobs)\n",
    "            param_grid = xg_param_grid\n",
    "            grid = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=K_folds, return_train_score=False, refit=False)\n",
    "            grid.fit(X_train_val, y_train_val)\n",
    "            best_params[ens] = grid.best_params_\n",
    "            print(best_params)\n",
    "            first_mem = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XBG Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB-Specific Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_folds: cross validation; number of splits for training set (in this case 3 splits; see below)\n",
    "# Train on the first split, test on the remaining 2. Total 3 numbers for the final RMSE\n",
    "\n",
    "K_folds = 3       # Split training set into 3 parts\n",
    "approach = \"xg\"   # XGB approach\n",
    "first_mem = False # Initialize if using gridsearch to find best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the XBG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(random_state=random_seeds[5,seed_loc], **best_params[ens], n_jobs=jobs)\n",
    "model.fit(X_train_val, y_train_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the XBG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment when actually running\n",
    "\n",
    "# pre_saildrone now called utils, carry through this change\n",
    "utils.save_model(model, model_output_dir, approach, ens, member)\n",
    "print(datetime.datetime.now())\n",
    "print(ens)\n",
    "print(member)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Analysis on XBG Test Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some test error metrics and store in a dictionary\n",
    "# evaluate_test is a function from pre_saildrone. it includes MSE, MAE, bias etc\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "test_performance[ens][member] = utils.evaluate_test(y_test, y_pred_test)\n",
    "print(test_performance[ens][member])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo this analysis on the unseen data\n",
    "y_pred_unseen = model.predict(df.loc[unseen_sel,features_sel].to_numpy())\n",
    "\n",
    "y_unseen = df.loc[unseen_sel,target_sel].to_numpy().ravel()\n",
    "unseen_performance[ens][member] = utils.evaluate_test(y_unseen, y_pred_unseen)\n",
    "print(unseen_performance[ens][member])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reconstruction and save it\n",
    "# Jake calls it seen\n",
    "# This should just be all SOCAT locations for all training years (not test years)\n",
    "y_pred_seen = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full reconstruction \n",
    "df['pCO2_DIC_recon'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_recon']] = y_pred_unseen   # Not in a SOCAT location, not even in test year\n",
    "df.loc[sel,['pCO2_DIC_recon']] = y_pred_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All time/locations not sampled by SOCAT\n",
    "df['pCO2_DIC_nosocat'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_nosocat']] = y_pred_unseen\n",
    "df.loc[sel,['pCO2_DIC_nosocat']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only at time/locations of SOCAT sampling\n",
    "df['pCO2_DIC_socat'] = np.nan\n",
    "df.loc[unseen_sel,['pCO2_DIC_socat']] = np.nan\n",
    "df.loc[sel,['pCO2_DIC_socat']] = y_pred_seen\n",
    "     \n",
    "df['pCO2_DIC'] = df['pCO2_pCO2T_diff']\n",
    "             \n",
    "#DS_recon = df[['net_mask','socat_mask','pCO2_DIC','pCO2_DIC_recon','pCO2_DIC_socat','pCO2_DIC_nosocat']].to_xarray()\n",
    "DS_recon = df[['net_mask','combined_mask','pCO2_DIC','pCO2_DIC_recon','pCO2_DIC_socat','pCO2_DIC_nosocat']].to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when actually running            \n",
    "#pre_saildrone_thea.save_recon(DS_recon, recon_output_dir, approach, ens, member)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save best parameters and performace metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving best parameters and performance metrics\n",
    "\n",
    "approach_output_dir = f\"{other_output_dir}/{approach}\"\n",
    "param_fname = f\"{approach_output_dir}/{approach}_best_params_dict.pickle\"\n",
    "test_perform_fname = f\"{approach_output_dir}/{approach}_test_performance_dict.pickle\"\n",
    "unseen_perform_fname = f\"{approach_output_dir}/{approach}_unseen_performance_dict.pickle\"\n",
    "\n",
    "Path(approach_output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(param_fname, 'wb') as handle: #WHAT DOES wb MEAN\n",
    "    pickle.dump(best_params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(test_perform_fname, 'wb') as handle:\n",
    "    pickle.dump(test_performance, handle)\n",
    "with open(unseen_perform_fname, 'wb') as handle:\n",
    "    pickle.dump(unseen_performance, handle)\n",
    "    \n",
    "# Convert performance metrics to dataframes\n",
    "test_df = pd.DataFrame.from_dict({(i,j): test_performance[i][j]\n",
    "                                  for i in test_performance.keys()\n",
    "                                  for j in test_performance[i].keys()},\n",
    "                                 orient='index')\n",
    "\n",
    "unseen_df = pd.DataFrame.from_dict({(i,j): unseen_performance[i][j]\n",
    "                                  for i in unseen_performance.keys()\n",
    "                                  for j in unseen_performance[i].keys()},\n",
    "                                 orient='index')\n",
    "\n",
    "test_df.index.names = [\"model\",\"member\"]\n",
    "unseen_df.index.names = [\"model\",\"member\"]\n",
    "\n",
    "# Save the dataframes too\n",
    "test_df_fname = f\"{approach_output_dir}/{approach}_test_performance_df.pickle\"\n",
    "unseen_df_fname = f\"{approach_output_dir}/{approach}_unseen_performance_df.pickle\"\n",
    "\n",
    "test_df.to_pickle(test_df_fname)\n",
    "unseen_df.to_pickle(unseen_df_fname)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just checking what the saved trained datafiles look like \n",
    "test_2 = pd.read_pickle(\"/data/artemis/workspace/theimdal/saildrone/models/trained/xg/CESM/member_016/xg_model_pC02_2D_mon_CESM_016_1x1_198201-201701.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking out what the input data for the XGB looks like\n",
    "#this table was generated in script 01\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fromML",
   "language": "python",
   "name": "fromml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
